{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30588,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n#import cudf\n#%reload_ext cudf.pandas\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.signal import get_window\nfrom tqdm.auto import tqdm\n\n!nvidia-smi\n!nvcc --version\nprint(torch.__version__)\ntorch.cuda.is_available()\n\n#print(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T08:11:11.615230Z","iopub.execute_input":"2023-12-17T08:11:11.615511Z","iopub.status.idle":"2023-12-17T08:11:18.334881Z","shell.execute_reply.started":"2023-12-17T08:11:11.615486Z","shell.execute_reply":"2023-12-17T08:11:18.333749Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Sun Dec 17 08:11:17 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\n2.0.0\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"raw_train_series = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet')\nprint(raw_train_series)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T08:11:19.346826Z","iopub.execute_input":"2023-12-17T08:11:19.347475Z","iopub.status.idle":"2023-12-17T08:12:01.436135Z","shell.execute_reply.started":"2023-12-17T08:11:19.347448Z","shell.execute_reply":"2023-12-17T08:12:01.435011Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"              series_id    step                 timestamp     anglez    enmo\n0          038441c925bb       0  2018-08-14T15:30:00-0400   2.636700  0.0217\n1          038441c925bb       1  2018-08-14T15:30:05-0400   2.636800  0.0215\n2          038441c925bb       2  2018-08-14T15:30:10-0400   2.637000  0.0216\n3          038441c925bb       3  2018-08-14T15:30:15-0400   2.636800  0.0213\n4          038441c925bb       4  2018-08-14T15:30:20-0400   2.636800  0.0215\n...                 ...     ...                       ...        ...     ...\n127946335  fe90110788d2  592375  2017-09-08T00:14:35-0400 -27.277500  0.0204\n127946336  fe90110788d2  592376  2017-09-08T00:14:40-0400 -27.032499  0.0233\n127946337  fe90110788d2  592377  2017-09-08T00:14:45-0400 -26.841200  0.0202\n127946338  fe90110788d2  592378  2017-09-08T00:14:50-0400 -26.723900  0.0199\n127946339  fe90110788d2  592379  2017-09-08T00:14:55-0400 -31.521601  0.0205\n\n[127946340 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_train_events = pd.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv')\nraw_test_series = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet')\nprint(raw_train_events)\nprint(raw_test_series)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T08:17:22.577845Z","iopub.execute_input":"2023-12-17T08:17:22.578668Z","iopub.status.idle":"2023-12-17T08:17:22.637647Z","shell.execute_reply.started":"2023-12-17T08:17:22.578635Z","shell.execute_reply":"2023-12-17T08:17:22.636709Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"          series_id  night   event      step                 timestamp\n0      038441c925bb      1   onset    4992.0  2018-08-14T22:26:00-0400\n1      038441c925bb      1  wakeup   10932.0  2018-08-15T06:41:00-0400\n2      038441c925bb      2   onset   20244.0  2018-08-15T19:37:00-0400\n3      038441c925bb      2  wakeup   27492.0  2018-08-16T05:41:00-0400\n4      038441c925bb      3   onset   39996.0  2018-08-16T23:03:00-0400\n...             ...    ...     ...       ...                       ...\n14503  fe90110788d2     33  wakeup  560604.0  2017-09-06T04:07:00-0400\n14504  fe90110788d2     34   onset  574620.0  2017-09-06T23:35:00-0400\n14505  fe90110788d2     34  wakeup  581604.0  2017-09-07T09:17:00-0400\n14506  fe90110788d2     35   onset       NaN                       NaN\n14507  fe90110788d2     35  wakeup       NaN                       NaN\n\n[14508 rows x 5 columns]\n        series_id  step                 timestamp     anglez    enmo\n0    038441c925bb     0  2018-08-14T15:30:00-0400   2.636700  0.0217\n1    038441c925bb     1  2018-08-14T15:30:05-0400   2.636800  0.0215\n2    038441c925bb     2  2018-08-14T15:30:10-0400   2.637000  0.0216\n3    038441c925bb     3  2018-08-14T15:30:15-0400   2.636800  0.0213\n4    038441c925bb     4  2018-08-14T15:30:20-0400   2.636800  0.0215\n..            ...   ...                       ...        ...     ...\n445  0402a003dae9   145  2018-12-18T12:57:05-0500 -59.696899  0.0601\n446  0402a003dae9   146  2018-12-18T12:57:10-0500 -35.656601  0.0427\n447  0402a003dae9   147  2018-12-18T12:57:15-0500 -21.582399  0.0309\n448  0402a003dae9   148  2018-12-18T12:57:20-0500 -42.616001  0.0328\n449  0402a003dae9   149  2018-12-18T12:57:25-0500   7.029900  0.0081\n\n[450 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# All steps that can be done easier with dataframes done here\ndef filter_id(raw_data, id_list):\n    return raw_data[raw_data['series_id'].isin(id_list)].dropna()\n\ndef common_ppro(raw_data):\n    data = raw_data.dropna()\n    data = data.drop(columns = ['timestamp']) # Each step = 5 seconds\n    # data = data.drop(columns = ['step']) # Each column = 1 step\n    # turn series_id into int; use range(len(train_ids)) to access ids\n    data['series_id'], _ = pd.factorize(data['series_id'])\n    data = data.astype(float)\n    \n    return data\n\ndef train_val_split(data, id_list, val_ratio):\n    train_n = int(len(id_list) * (1 - val_ratio))\n    \n    train_data = data[data['series_id'] < train_n]\n    val_data = data[data['series_id'] >= train_n]\n    \n    return train_data, val_data\n\ndef dloader(raw_series, raw_events):\n    ## restrict to first 3 ids for training; remove later\n    id_list = list(set(raw_events['series_id'].tolist()))\n    #id_list = id_list[:3]\n    series, events = filter_id(raw_series, id_list).dropna(), filter_id(raw_events, id_list).dropna()\n    # series, events = (raw_series.dropna(), raw_events.dropna())\n    \n    ## split series into series_id & nights column\n    ## -> training will occur with each night as input\n    night_secs = int(3600 * 24 / 5) # 5 secs per step\n    series.insert(loc = series.columns.get_loc('series_id') + 1, column = 'night',\n               value = series['step'].apply(lambda x : int(x / night_secs)) + 1)\n    \n    ## filter series for nights where an event occurs\n    events_single = events[events['event'] == 'onset']\n    series = pd.merge(series, events_single[['series_id', 'night']], on = ['series_id', 'night'], how = 'inner')\n    \n    ## events to numerical columns\n    events = pd.get_dummies(events, columns = ['event'])\n    \n    ## common preprocessing\n    series, events = common_ppro(series), common_ppro(events)\n    \n    ## train_val_split\n    val_ratio = 0.2\n    train_series, val_series = train_val_split(series, id_list, val_ratio)\n    train_events, val_events = train_val_split(events, id_list, val_ratio)\n    \n    return train_series, train_events, val_series, val_events","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:19:14.419889Z","iopub.execute_input":"2023-12-01T18:19:14.420335Z","iopub.status.idle":"2023-12-01T18:19:14.435922Z","shell.execute_reply.started":"2023-12-01T18:19:14.420298Z","shell.execute_reply":"2023-12-01T18:19:14.434798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_series, train_events, val_series, val_events = dloader(raw_train_series, raw_train_events)\n\ndef series_to_tensor(series):\n    grouped = series.groupby(['series_id', 'night'])\n    tensors = {}\n    for (sid, night), group in grouped:\n        tensors[(sid, night)] = torch.tensor(group.iloc[:, 2:].values, dtype = torch.float32, device = 'cuda')\n    return tensors\n    \ndef df_to_tensor(df):\n    return torch.tensor(df.values, dtype = torch.float32, device = 'cuda')\n\ntrain_t, val_t = series_to_tensor(train_series), series_to_tensor(val_series)\ntrain_e, val_e = series_to_tensor(train_events), series_to_tensor(val_events)\n\ntest_id_list = list(set(raw_test_series['series_id'].tolist()))\ntest_series = common_ppro(raw_test_series)\ntest_t = df_to_tensor(test_series)\n# data format : id, step, anglez, enmo, event_onsent, event_wakeup","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:19:28.953210Z","iopub.execute_input":"2023-12-01T18:19:28.954089Z","iopub.status.idle":"2023-12-01T18:23:09.036749Z","shell.execute_reply.started":"2023-12-01T18:19:28.954054Z","shell.execute_reply":"2023-12-01T18:23:09.035477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing : all processes are iterated over individual series_id and night\n# acess by train_t[(series_id, night)]\n\n## frequency space : short time fourier transform\n\ndef label(step, event):\n    if event.size(0) == 2:\n        onset_s, wakeup_s = event[0][0], event[1][0]\n    else:\n        if event[0][1] == 1.0: # event_onset\n            onset_s, wakeup_s = event[0][0], float('inf')\n        else:\n            onset_s, wakeup_s = float('-inf'), event[0][0]\n            \n    label_b = (step >= onset_s) & (step <= wakeup_s)\n    return label_b.to(dtype = torch.float32, device = 'cuda')\n\ndef segment(data, wdw_size, hop_size):\n    # data : N * 3 tensor\n    # dim 0 : size N, time series (step); equals data.size(0)\n    # dim 1 : size 3 vector : step, anglez, enmo\n    \n    wdw_cnt = int((data.size(0) - wdw_size - 1) / hop_size) + 1\n    shape = (wdw_cnt, wdw_size, 3)\n    stride = (hop_size * 3, 3, 1)\n    \n    # segmented_data : seg_len * wdw_size * 3 tensor\n    # dim 0 : size wdw_cnt, column of segments\n    # dim 1 : size wdw_size, each segment with wdw_size time series points\n    # dim 2 : size 3 vector : step, anglez, enmo\n    seg_data = torch.as_strided(data, shape, stride)\n    return seg_data\n\ndef slidevar(tensor, window_size = 4):\n    var = torch.zeros(tensor.size(), device='cuda', dtype=torch.float32)\n    \n    for i in range(0, tensor.size(0) - window_size + 1, window_size):\n        end_idx = min(i + window_size, tensor.size(0) - window_size + 1)\n        window = tensor[i:end_idx + window_size - 1]\n        var[i:end_idx] = torch.var(window, dim=0, unbiased=False)\n\n    return var\n\ndef stft(seg_data):\n    average_step = torch.mean(seg_data[:, :, 0], dim = 1).view(-1,1)\n    anglez_data = seg_data[:, :, 1]\n    enmo_data = seg_data[:, :, 2]\n    \n    # dim 0 : size wdw_cnt, column of segments\n    # dim 1 : size wdw_size, each segment with frequency space magnitude\n    anglez_fft = torch.abs(torch.fft.fft(anglez_data, dim = 1))\n    enmo_fft = torch.abs(torch.fft.fft(enmo_data, dim = 1))\n    \n    # dim 0 : column of segments\n    # dim 1 : step, angle/enmo frequency space magnitude (1 + 8 + 8 columns)\n    # total_fft = torch.concat((average_step, anglez_fft, enmo_fft), dim = 1)\n\n    # anglez_freq_max = torch.argmax(anglez_fft, dim=1).view(-1, 1).float() # Convert indices to float for concatenation\n    # enmo_freq_max = torch.argmax(enmo_fft, dim=1).view(-1, 1).float()\n\n    # dim 1 : step, angle/enmo frequency variance + frequency with maximum amplitude (1 + 2 + 2 columns)\n    # total_fft = torch.cat((average_step, anglez_var, anglez_freq_max, enmo_var, enmo_freq_max), dim=1)\n    anglez_var = slidevar(anglez_fft)\n    enmo_var = slidevar(enmo_fft)\n    total_fft = torch.cat((average_step, anglez_var, enmo_var), dim=1)\n    \n    # columnwise regularisation of variance; also performed individually for each dataset\n    total_fft[:,1] = total_fft[:,1] / torch.mean(total_fft[:,1])\n    total_fft[:,2] = total_fft[:,2] / torch.mean(total_fft[:,2])\n\n    return total_fft\n\ndef train_f(datadict, event):\n    tensors = {}\n    labels = {}\n    ## empirical average of movement time : 8 steps\n    wdw_size = 8\n    ## hop between time segments; not equal to wdw_size to prevent boundary issues\n    hop_size = 6\n    \n    # dictionary of tensors, access by tensors[(sid, night)]\n    for sid, night in tqdm(datadict, desc = \"Processing\"):\n        data = datadict[(sid, night)]\n        t_seg = stft(segment(data.contiguous(), wdw_size, hop_size))\n        # t_seg[:,0] : column of steps\n        # event[(sid, night)] : should be in form of ((step, 1, 0), (step, 0, 1))\n        t_label = label(t_seg[:,0], event[(sid, night)]).view(-1, 1)\n        \n        tensors[(sid, night)], labels[(sid, night)] = t_seg, t_label\n        \n    return tensors, labels\n\nx_train_seg, y_train_seg = train_f(train_t, train_e)\nx_val_seg, y_val_seg = train_f(val_t, val_e)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T18:14:11.419835Z","iopub.status.idle":"2023-12-01T18:14:11.420265Z","shell.execute_reply.started":"2023-12-01T18:14:11.420060Z","shell.execute_reply":"2023-12-01T18:14:11.420078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\n\n# training\n## hyperparamters\nepoch_n = 20\neta_p = 0.1 # learning rate\nbatch_size = 100\nC = 0 #0.001\n\nclass Data(Dataset):\n    def __init__(self, series_data, event_data):\n        self.series_data = series_data\n        self.event_data = event_data\n        self.keys = list(event_data.keys())\n\n    def __len__(self):\n        return len(self.series_data)\n\n    def __getitem__(self, idx):\n        series = self.series_data[self.keys[idx]]\n        event = self.event_data[self.keys[idx]]\n        length = series.size(0)\n        return series, event, length\n\ndef collate(batch):\n    series, events, lengths = zip(*batch)\n    series_padded = pad_sequence(series, batch_first = True)\n    events_padded = pad_sequence(events, batch_first = True)\n    \n    lengths = torch.tensor(lengths, dtype = torch.float32, device = 'cuda')\n\n    return series_padded, events_padded, lengths\n\ntrain_dataset = Data(x_train_seg, y_train_seg)\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, collate_fn = collate)\n\n\"\"\"# heuristic : variance / frequency space of output is relevant\ndef variance(tensor, window_size = 5):\n    var = torch.zeros_like(tensor).to(dtype = torch.float32, device = 'cuda')\n\n    # Compute variance for each window\n    for i in range(tensor.size(0) - window_size):\n        window = tensor[i:i + window_size]\n        var[i] = torch.var(window, unbiased = False)  # Set unbiased to False for sample variance\n\n    return var\n\nreg = 50000 # uniform regularisation of outputs; replace with regularisation of initial frequency data?\nthres = 1e-4\"\"\"\n\nclass SVM(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.lin = nn.Linear(input_dim, 1) # 1 class\n\n    def forward(self, x):\n        #outputs = torch.sigmoid(self.lin(x))\n        outputs = self.lin(x).to(device = 'cuda')\n        #outputs = variance(outputs) / reg # low variance : sleep, high variance : awake, 50000 : regularisation\n        return outputs\n    \ndef train_model(model, optimiser, loader):\n    model.train()\n    for epoch in range(epoch_n):\n        total_loss = 0\n        for batch_id, (data, target, lengths) in enumerate(loader):\n            data, target = data.to(device = 'cuda')[:,:,1:], target.to(device = 'cuda')\n            optimiser.zero_grad()\n            output = model(data)\n            \n            hinge_loss = torch.mean(torch.clamp(1 - output * target, min=0)) # error\n            loss = hinge_loss + C * torch.norm(model.lin.weight, 2)\n            \n            loss.backward()\n            optimiser.step()\n            \n            total_loss += loss\n        #print(f'Epoch [{epoch+1}/{epoch_n}], Loss: {total_loss/len(loader)}')\n    \n    return model","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T18:14:11.421220Z","iopub.status.idle":"2023-12-01T18:14:11.421611Z","shell.execute_reply.started":"2023-12-01T18:14:11.421419Z","shell.execute_reply":"2023-12-01T18:14:11.421439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classifier(data):\n    outputs = (data < thres).int().to(dtype = torch.float32, device = 'cuda')\n    # consider size of window used in variance above; add 2 to each ends of sleep intervals\n    # change filter above to incorporate this? existence of value beneath threshold in +-2\n    return outputs\n\ndef intervals_f(data):\n    diff = torch.diff(data, prepend = data[0:1], append = data[-1:])\n    starts = (diff == 1).nonzero(as_tuple=True)[0]\n    ends = (diff == -1).nonzero(as_tuple=True)[0]\n    \n    if data[0] == 1:\n            starts = torch.cat((torch.tensor([0]).to(device = 'cuda'), starts))\n    if data[-1] == 1:\n            ends = torch.cat((ends, torch.tensor([len(data) - 1]).to(device = 'cuda')))\n            \n    intervals = list(zip(starts.tolist(), ends.tolist()))\n    \n    return intervals\n\ndef rm_dstrb(data, max_len_dstrb): # remove disturbances\n    \"\"\"sleep_interval_list = [[] for _ in range(batch_size)]\"\"\"\n    new_data = torch.zeros(data.shape).to(device = 'cuda')\n    \n    intervals = intervals_f(data)\n    \n    curr_int = intervals[0]\n    fin_int = (0,0)\n    \n    for i in range(1, len(intervals)):\n        if intervals[i][0] - curr_int[1] < max_len_dstrb:\n            curr_int = (curr_int[0], intervals[i][0])\n            if i == len(intervals) - 1:\n                fin_int = curr_int\n        else:\n            if (curr_int[1] - curr_int[0]) > (fin_int[1] - fin_int[0]):\n                fin_int = curr_int\n            curr_int = intervals[i]\n    \n    new_data[fin_int[0]:fin_int[1]+1] = 1\n            \n    return new_data\n\n#def sleepinterval(data):\n    # obtain sleep interval from raw data, in order to obtain confidence interval\n    # consider size of window used in variance above; add 2 to each ends of sleep intervals\n\ndef confuse(sid, night, true, pred):\n    n = true.size(0)\n    t_pos = torch.sum((true == 1) & (pred == 1))/n\n    f_pos = torch.sum((true == 0) & (pred == 1))/n\n    f_neg = torch.sum((true == 1) & (pred == 0))/n\n    t_neg = torch.sum((true == 0) & (pred == 0))/n\n    \n    accuracy = (round((t_pos + t_neg).item(), 2))\n    \n    #print('confusion : {}-{}-{}-{}'.format(t_pos, f_pos, f_neg, t_neg))\n    #print('accuracy : {}'.format(accuracy))\n    \n    return t_pos, f_pos, f_neg, t_neg, accuracy\n    \ndef val_model(model, predictor, label):\n    total_acc = 0\n    for sid, night in predictor:\n        #print(sid, night)\n        x = predictor[(sid, night)]\n        y = torch.squeeze(label[(sid, night)])\n        \n        output = classifier(model(x[:, 1:]))\n        output = torch.squeeze(torch.nn.functional.pad(output, (0, len(y) - len(output)), 'constant', 0))\n        doutput = rm_dstrb(output, x.size(0) * dstrb_ratio)\n        _, _, _, _, _ = confuse(sid, night, y, output)\n        tp, fp, fn, tn, b_acc = confuse(sid, night, y, doutput)\n        \n        #print(intervals_f(doutput))\n        \n        \"\"\"if a_acc > b_acc:\n            print(a_acc, b_acc)\n            for i in range(len(y)):\n                print(output[i].item(), doutput[i].item(), y[i].item())\"\"\"\n        \n        total_acc += b_acc\n    \n    return total_acc\n\n\"\"\"val_dataset = Data(x_val_seg, y_val_seg)\nval_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True, collate_fn = collate)\"\"\"","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T18:14:11.423574Z","iopub.status.idle":"2023-12-01T18:14:11.424006Z","shell.execute_reply.started":"2023-12-01T18:14:11.423784Z","shell.execute_reply":"2023-12-01T18:14:11.423802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SVM(16).to('cuda')\noptimiser = optim.SGD(model.parameters(), lr = eta_p)\nmodel = train_model(model, optimiser, train_loader)\n\ndstrb_ratio = 0.044 # 30 minutes or less of wake between sleeps can be inverted\n\"\"\"for i in range(10, 20, 1):\n    thres = i/10\n    try:\n        total_acc = val_model(model, x_val_seg, y_val_seg)\n    except:\n        print(i, 'oops')\n    print(i/10, total_acc/len(x_val_seg))\"\"\"\n\nthres = 1.1\n\"\"\"for i in range(40, 60, 1):\n    dstrb_ratio = i / 1000\n    total_acc = val_model(model, x_val_seg, y_val_seg)\n    print(i/1000, total_acc/len(x_val_seg))\"\"\"\n\ntotal_acc = val_model(model, x_val_seg, y_val_seg)\nprint(total_acc/len(x_val_seg))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:14:11.425580Z","iopub.status.idle":"2023-12-01T18:14:11.426184Z","shell.execute_reply.started":"2023-12-01T18:14:11.425901Z","shell.execute_reply":"2023-12-01T18:14:11.425923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_model(model, series):\n    results = {}\n    ## empirical average of movement time : 8 steps\n    wdw_size = 8\n    ## hop between time segments; not equal to wdw_size to prevent boundary issues\n    hop_size = 6\n    \n    for sid in range(3):\n        data = series[series[:,0] == sid][:]\n        data = data[:,1:]\n        seg = segment(data.contiguous(), wdw_size, hop_size)\n        x = stft(seg)\n        output = torch.squeeze(classifier(model(x[:, 1:])))\n        doutput = rm_dstrb(output, x.size(0) * dstrb_ratio)\n        \n        intv = intervals_f(output)[0]\n        results[sid] = (round(x[intv[0]][0].item(),0), round(x[intv[1]][0].item(),0))\n    \n    return results\n\nitern = 40\n\ntotal_results = []\n\nfor _ in range(itern):\n    model = SVM(16).to('cuda')\n    optimiser = optim.SGD(model.parameters(), lr = eta_p)\n    model = train_model(model, optimiser, train_loader)\n    \n    results = test_model(model, test_t)\n    \n    total_results.append(results)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:14:11.428515Z","iopub.status.idle":"2023-12-01T18:14:11.429159Z","shell.execute_reply.started":"2023-12-01T18:14:11.428875Z","shell.execute_reply":"2023-12-01T18:14:11.428905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizsiz = len(total_results[0])\nids, avg, event, err = [0]*sizsiz*2, [0]*sizsiz*2, [0]*sizsiz*2, [0]*sizsiz*2\nfor t, data in enumerate(total_results):\n    for i in range(sizsiz):\n        avg[2*i] += data[i][0]\n        ids[2*i] = test_id_list[i]\n        event[2*i] = 'onset'\n        avg[2*i+1] += data[i][1]\n        event[2*i+1] = 'wakeup'\n        ids[2*i+1] = test_id_list[i]\n        err[2*i] += (data[i][0] - avg[2*i]/(t+1))**2\n        err[2*i+1] += (data[i][1] - avg[2*i+1]/(t+1))**2\n        \navg = np.array(avg) // len(total_results)\nerr = 1 - np.arctan(np.sqrt(np.array(err)) / len(total_results))/(np.pi / 2)\n\ndata = {\n    'series_id' : ids,\n    'step' : avg,\n    'event' : event,\n    'score' : err\n}\n\nfinalframe = pd.DataFrame(data)\nfinalframe.index.name = 'row_id'\n\nprint(finalframe)\n\nfinalframe.to_csv('/kaggle/working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:14:11.431122Z","iopub.status.idle":"2023-12-01T18:14:11.431644Z","shell.execute_reply.started":"2023-12-01T18:14:11.431403Z","shell.execute_reply":"2023-12-01T18:14:11.431426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}