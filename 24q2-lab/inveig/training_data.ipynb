{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FPKx04IwJu"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "import scipy.sparse as sparse\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def seq_mlp(init, mlp, fin, act):\n",
        "    modules = [nn.Linear(init, mlp[0]), act]\n",
        "    for i in range(len(mlp) - 1):\n",
        "        modules.append(nn.Linear(mlp[i], mlp[i+1]))\n",
        "        modules.append(act)\n",
        "\n",
        "    modules.append(nn.Linear(mlp[-1], fin)) #self.spl for spline\n",
        "\n",
        "    return modules"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "uVysTeoK8k"
      },
      "source": [
        "class EvalEig(nn.Module):\n",
        "    def __init__(self, eval_para):\n",
        "        super().__init__()\n",
        "        self.bd = eval_para['batch_dim']\n",
        "\n",
        "    def set_rdsc(self, xm, xn, p_num):\n",
        "        self.xn = xn\n",
        "        self.xm = xm\n",
        "        self.pn = p_num\n",
        "    \n",
        "    def mesh_ptl(self, posx, posy): # input shape (bd, p_num)\n",
        "        X, Y = np.meshgrid(np.linspace(-self.xm, self.xm, self.xn),\n",
        "                            np.linspace(-self.xm, self.xm, self.xn), indexing = 'ij')\n",
        "        X_broad, Y_broad = X[np.newaxis,np.newaxis,:,:], Y[np.newaxis,np.newaxis,:,:]\n",
        "        posx_broad, posy_broad = posx[:,:,np.newaxis,np.newaxis], posy[:,:,np.newaxis,np.newaxis]\n",
        "\n",
        "        dist = np.sqrt((X_broad-posx_broad)**2+(Y_broad-posy_broad)**2)\n",
        "        dist[dist==0] = np.finfo(float).eps\n",
        "\n",
        "        ptl = np.sum(-1/dist,axis=1)\n",
        "        return ptl # shape (bd, xn, xn)\n",
        "    \n",
        "    def mesh_hml(self, term_ptl):\n",
        "        dx = 2*self.xm/(self.xn-1)\n",
        "        diag = [np.full(self.xn, -2/dx**2), np.full(self.xn-1, 1/dx**2), np.full(self.xn-1, 1/dx**2)]\n",
        "\n",
        "        term_kin_partial = sparse.diags(diag, [0,-1,1], shape=(self.xn,self.xn))\n",
        "        term_kin = sparse.kron(sparse.identity(self.xn), term_kin_partial) + \\\n",
        "            sparse.kron(term_kin_partial, sparse.identity(self.xn))\n",
        "        term_hml = term_kin + sparse.diags(term_ptl.ravel(), 0)\n",
        "        \n",
        "        return term_hml\n",
        "    \n",
        "    def init_evl(self):\n",
        "        posx = np.random.uniform(-self.xm, self.xm, size=(self.bd, self.pn))/10\n",
        "        posy = np.random.uniform(-self.xm, self.xm, size=(self.bd, self.pn))/10\n",
        "\n",
        "        evl = np.zeros((self.bd, 6)) # p_num as cutoff for number of smallest evls obtained? fix as 6?\n",
        "        mesh_ptl = self.mesh_ptl(posx, posy)\n",
        "\n",
        "        pbar = tqdm(range(self.bd), desc='Progress', total=self.bd, leave = True, position=0, colour='blue')\n",
        "\n",
        "        for i in range(self.bd):\n",
        "            mesh_hml = self.mesh_hml(mesh_ptl[i])\n",
        "            evl_i, _ = sparse.linalg.eigsh(mesh_hml, which = 'SM')\n",
        "            evl[i] = evl_i\n",
        "\n",
        "            pbar.update()\n",
        "        \n",
        "        return posx, posy, evl\n",
        "\n",
        "    def forward(self):\n",
        "        posx_tr, posy_tr, evl_tr = self.init_evl()\n",
        "\n",
        "        return posx_tr, posy_tr, evl_tr\n",
        "\n",
        "class InvEig(EvalEig):\n",
        "    def __init__(self, eval_para, model_para):\n",
        "        super().__init__(eval_para)\n",
        "        self.mlp_shape = model_para['mlp']\n",
        "\n",
        "    def set_rdsc(self, xm, xn, p_num):\n",
        "        self.xn = xn\n",
        "        self.xm = xm\n",
        "        self.pn = p_num\n",
        "\n",
        "        # initialise model\n",
        "        #self.ptl = nn.Parameter(torch.rand(self.batch_dim, self.rn-1)) # random parameters\n",
        "        modules = seq_mlp(init = 6, mlp = self.mlp_shape, fin = int(self.pn*(self.pn-1)/2), act = nn.ReLU())\n",
        "        self.mlp = nn.Sequential(*modules)\n",
        "    \n",
        "    def dist_tsor(self, posx, posy):\n",
        "        diffx = posx.unsqueeze(2) - posx.unsqueeze(1)\n",
        "        diffy = posy.unsqueeze(2) - posy.unsqueeze(1)\n",
        "        dist = diffx**2 + diffy**2\n",
        "\n",
        "        upptri_ind = torch.triu_indices(row=diffx.shape[1],col=diffx.shape[1],offset=1)\n",
        "        upptri_val = dist[:, upptri_ind[0], upptri_ind[1]]\n",
        "        val, _ = torch.sort(upptri_val)\n",
        "\n",
        "        return val/self.xm**2\n",
        "\n",
        "    def forward(self, evl):\n",
        "        #pos = self.mlp(evl)\n",
        "        #posx_md, posy_md = pos[:,:self.pn], pos[:,self.pn:]\n",
        "        #val_md = self.dist_tsor(posx_md, posy_md)\n",
        "        posx_md, posy_md = None, None \n",
        "        val_md = self.mlp(evl)\n",
        "\n",
        "        return posx_md, posy_md, val_md"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xXhJasuNef"
      },
      "source": [
        "eval_para = {\n",
        "        # model specifics\n",
        "        'precision' : 64, # 32 or 64 bit\n",
        "        'batch_dim' : 1000\n",
        "        }\n",
        "\n",
        "model_para = {\n",
        "        # model\n",
        "        'mlp' : [1000, 1000, 1000],\n",
        "\n",
        "        # training\n",
        "        'epoch' : 5000,\n",
        "        'lr' : 1e-2,\n",
        "\n",
        "        # loss regularisation\n",
        "        'reg1' : 1e-1, # V(0) sign\n",
        "        'reg2' : 1, # V -> 0 as r -> infty\n",
        "        \n",
        "        }\n",
        "\n",
        "eval = EvalEig(eval_para)\n",
        "eval.set_rdsc(xm = 1e4, xn = 100, p_num = 10)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "S7Cvn4f1LQ"
      },
      "source": [
        "#eval_grid = [[800], \\\n",
        "#    [10000], \\\n",
        "#        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] # rm, rn, para_1\n",
        "#for midx in itertools.product(*eval_grid):\n",
        "#for midx in zip(*eval_grid):\n",
        "    #eval.set_rdsc(midx[0], midx[1])\n",
        "    #ptl_tr = eval.fixed_tr(midx[2], \"coulomb\")\n",
        "    #evl_scl_tr = eval.dsc_eigs(ptl_tr)\n",
        "    #evl_tr = evl_scl_tr[:,:,:eval.evl_cutoff(evl_scl_tr)]\n",
        "#    ptl_tr, evl_tr = eval(midx[0], midx[1], midx[2], \"coulomb\")\n",
        "#    factor = torch.mean(1/evl_tr, dim = 0)\n",
        "#    print(factor[0])\n",
        "#    print(midx, nn.L1Loss()(factor[0],torch.arange(1,factor.shape[1]+1)**2), evl_tr[0,0,0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "dqqtMw4W8d"
      },
      "source": [
        "#posx_tr, posy_tr, evl_tr = eval()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "lnmGKmDP1w"
      },
      "source": [
        "#import pickle\n",
        "#with open(\"posx_tr.data\", \"wb\") as fw:\n",
        "#    pickle.dump(posx_tr, fw)\n",
        "#with open(\"posy_tr.data\", \"wb\") as fw:\n",
        "#    pickle.dump(posy_tr, fw)\n",
        "#with open(\"evl_tr.data\", \"wb\") as fw:\n",
        "#    pickle.dump(evl_tr, fw)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "vaDwRq94bB"
      },
      "source": [
        "import pickle\n",
        "with open(\"posx_tr.data\", \"rb\") as fr:\n",
        "    posx_tr = torch.from_numpy(pickle.load(fr)).to(dtype = torch.float32)\n",
        "with open(\"posy_tr.data\", \"rb\") as fr:\n",
        "    posy_tr = torch.from_numpy(pickle.load(fr)).to(dtype = torch.float32)\n",
        "with open(\"evl_tr.data\", \"rb\") as fr:\n",
        "    evl_tr = torch.from_numpy(pickle.load(fr)).to(dtype = torch.float32)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "tIwq7WLkxg"
      },
      "source": [
        "model = InvEig(eval_para, model_para)\n",
        "model.set_rdsc(xm = 1e4, xn = 1000, p_num = 10)\n",
        "#model.load_state_dict(torch.load('1.pth'))\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr = model_para['lr'])\n",
        "epochs = model_para['epoch']\n",
        "pbar = tqdm(range(epochs), desc='Progress', total=epochs, leave = True, position=0, colour='blue')\n",
        "loss_list = [[]]\n",
        "\n",
        "val_tr = model.dist_tsor(posx_tr, posy_tr).to(dtype = torch.float32)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "hCHoYCR6v7"
      },
      "source": [
        "for e in range(epochs):\n",
        "    #with torch.autograd.detect_anomaly():\n",
        "    posx_md, posy_md, val_md = model(evl_tr)\n",
        "    if e == 0:\n",
        "        val_init = val_md\n",
        "\n",
        "    loss = nn.L1Loss()(val_tr, val_md)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    pbar.update()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "e9rRdHJzmQ"
      },
      "source": [
        "torch.save(model.state_dict(), f\"{eval_para['batch_dim']}.pth\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "juRRVNYsNY"
      },
      "source": [
        "print(val_tr)\n",
        "print(val_init)\n",
        "print(val_md)\n",
        "print(loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "tensor([[0.0264, 0.0167, 0.0254,  ..., 0.0244, 0.0155, 0.0033],\n        [0.0142, 0.0094, 0.0030,  ..., 0.0212, 0.0085, 0.0031],\n        [0.0394, 0.0404, 0.0172,  ..., 0.0053, 0.0058, 0.0142],\n        ...,\n        [0.0200, 0.0008, 0.0236,  ..., 0.0124, 0.0015, 0.0064],\n        [0.0016, 0.0116, 0.0082,  ..., 0.0033, 0.0075, 0.0092],\n        [0.0051, 0.0002, 0.0022,  ..., 0.0033, 0.0253, 0.0118]])\ntensor([[-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221],\n        [-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221],\n        [-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221],\n        ...,\n        [-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221],\n        [-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221],\n        [-0.0067,  0.0222, -0.0462,  ..., -0.0608,  0.0395, -0.0221]],\n       grad_fn=<AddmmBackward0>)\ntensor([[0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103],\n        [0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103],\n        [0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103],\n        ...,\n        [0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103],\n        [0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103],\n        [0.0110, 0.0109, 0.0104,  ..., 0.0106, 0.0100, 0.0103]],\n       grad_fn=<AddmmBackward0>)\ntensor(0.0088, grad_fn=<MeanBackward0>)\n"
        }
      ],
      "execution_count": 1
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}